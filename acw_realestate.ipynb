{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brokered_by</th>\n",
       "      <th>status</th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "      <th>prev_sold_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103378.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1962661.0</td>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>601.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52707.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1902874.0</td>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>601.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103379.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1404990.0</td>\n",
       "      <td>Juana Diaz</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>795.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31239.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1947675.0</td>\n",
       "      <td>Ponce</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>731.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34632.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>331151.0</td>\n",
       "      <td>Mayaguez</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>680.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226377</th>\n",
       "      <td>23009.0</td>\n",
       "      <td>sold</td>\n",
       "      <td>359900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>353094.0</td>\n",
       "      <td>Richland</td>\n",
       "      <td>Washington</td>\n",
       "      <td>99354.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>2022-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226378</th>\n",
       "      <td>18208.0</td>\n",
       "      <td>sold</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1062149.0</td>\n",
       "      <td>Richland</td>\n",
       "      <td>Washington</td>\n",
       "      <td>99354.0</td>\n",
       "      <td>1616.0</td>\n",
       "      <td>2022-03-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226379</th>\n",
       "      <td>76856.0</td>\n",
       "      <td>sold</td>\n",
       "      <td>440000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>405677.0</td>\n",
       "      <td>Richland</td>\n",
       "      <td>Washington</td>\n",
       "      <td>99354.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>2022-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226380</th>\n",
       "      <td>53618.0</td>\n",
       "      <td>sold</td>\n",
       "      <td>179900.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>761379.0</td>\n",
       "      <td>Richland</td>\n",
       "      <td>Washington</td>\n",
       "      <td>99354.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>2022-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226381</th>\n",
       "      <td>108243.0</td>\n",
       "      <td>sold</td>\n",
       "      <td>580000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>307704.0</td>\n",
       "      <td>Richland</td>\n",
       "      <td>Washington</td>\n",
       "      <td>99354.0</td>\n",
       "      <td>3615.0</td>\n",
       "      <td>2022-03-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2226382 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         brokered_by    status     price  bed  bath  acre_lot     street  \\\n",
       "0           103378.0  for_sale  105000.0  3.0   2.0      0.12  1962661.0   \n",
       "1            52707.0  for_sale   80000.0  4.0   2.0      0.08  1902874.0   \n",
       "2           103379.0  for_sale   67000.0  2.0   1.0      0.15  1404990.0   \n",
       "3            31239.0  for_sale  145000.0  4.0   2.0      0.10  1947675.0   \n",
       "4            34632.0  for_sale   65000.0  6.0   2.0      0.05   331151.0   \n",
       "...              ...       ...       ...  ...   ...       ...        ...   \n",
       "2226377      23009.0      sold  359900.0  4.0   2.0      0.33   353094.0   \n",
       "2226378      18208.0      sold  350000.0  3.0   2.0      0.10  1062149.0   \n",
       "2226379      76856.0      sold  440000.0  6.0   3.0      0.50   405677.0   \n",
       "2226380      53618.0      sold  179900.0  2.0   1.0      0.09   761379.0   \n",
       "2226381     108243.0      sold  580000.0  5.0   3.0      0.31   307704.0   \n",
       "\n",
       "               city        state  zip_code  house_size prev_sold_date  \n",
       "0          Adjuntas  Puerto Rico     601.0       920.0            NaN  \n",
       "1          Adjuntas  Puerto Rico     601.0      1527.0            NaN  \n",
       "2        Juana Diaz  Puerto Rico     795.0       748.0            NaN  \n",
       "3             Ponce  Puerto Rico     731.0      1800.0            NaN  \n",
       "4          Mayaguez  Puerto Rico     680.0         NaN            NaN  \n",
       "...             ...          ...       ...         ...            ...  \n",
       "2226377    Richland   Washington   99354.0      3600.0     2022-03-25  \n",
       "2226378    Richland   Washington   99354.0      1616.0     2022-03-25  \n",
       "2226379    Richland   Washington   99354.0      3200.0     2022-03-24  \n",
       "2226380    Richland   Washington   99354.0       933.0     2022-03-24  \n",
       "2226381    Richland   Washington   99354.0      3615.0     2022-03-23  \n",
       "\n",
       "[2226382 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read data and create dataframe\n",
    "#NOTE: file too large to open in excel\n",
    "\n",
    "realestate_df = pd.read_csv(r\"C:\\Desktop\\Analysis Projects\\Testing_project_4\\Resources\\realtor-data.zip.csv.zip\")\n",
    "realestate_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types of columns:\n",
      "brokered_by       float64\n",
      "status             object\n",
      "price             float64\n",
      "bed               float64\n",
      "bath              float64\n",
      "acre_lot          float64\n",
      "street            float64\n",
      "city               object\n",
      "state              object\n",
      "zip_code          float64\n",
      "house_size        float64\n",
      "prev_sold_date     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display the data types of the columns\n",
    "column_dtypes = realestate_df.dtypes\n",
    "print(\"Data types of columns:\")\n",
    "print(column_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Duplicate Rows: 0\n"
     ]
    }
   ],
   "source": [
    "#Checking to see if there are duplicates in the dataset\n",
    "# Count duplicate rows based on all columns\n",
    "num_duplicate_rows = realestate_df.duplicated().sum()\n",
    "\n",
    "# Display the number of duplicate rows\n",
    "print(f\"Number of Duplicate Rows: {num_duplicate_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the original file as csv \n",
    "# Define the file path for the CSV output\n",
    "output_file_path = 'original_realtor_df.csv'\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "realestate_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103378.0, 'for_sale', 105000.0, 3.0, 2.0, 0.12, 1962661.0, 'Adjuntas', 'Puerto Rico', 601.0, 920.0, None)\n",
      "(52707.0, 'for_sale', 80000.0, 4.0, 2.0, 0.08, 1902874.0, 'Adjuntas', 'Puerto Rico', 601.0, 1527.0, None)\n",
      "(103379.0, 'for_sale', 67000.0, 2.0, 1.0, 0.15, 1404990.0, 'Juana Diaz', 'Puerto Rico', 795.0, 748.0, None)\n",
      "(31239.0, 'for_sale', 145000.0, 4.0, 2.0, 0.1, 1947675.0, 'Ponce', 'Puerto Rico', 731.0, 1800.0, None)\n",
      "(34632.0, 'for_sale', 65000.0, 6.0, 2.0, 0.05, 331151.0, 'Mayaguez', 'Puerto Rico', 680.0, None, None)\n"
     ]
    }
   ],
   "source": [
    "#Read data and create dataframe\n",
    "\n",
    "realestate_df = pd.read_csv(r\"C:\\Desktop\\Analysis Projects\\Testing_project_4\\Resources\\realtor-data.zip.csv.zip\")\n",
    "realestate_df\n",
    "\n",
    "# Create a SQLite database engine\n",
    "engine = create_engine('sqlite:///realestate.db')\n",
    "\n",
    "# Write DataFrame to SQLite database\n",
    "realestate_df.to_sql('realestate', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Confirm the data has been written by querying the database\n",
    "query = \"SELECT * FROM realestate LIMIT 5;\"  # Example query\n",
    "result = engine.execute(query)\n",
    "for row in result:\n",
    "    print(row)\n",
    "\n",
    "# Close the database connection\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State counts:\n",
      "Florida                 249432\n",
      "California              227215\n",
      "Texas                   208335\n",
      "New York                103159\n",
      "North Carolina           85745\n",
      "Illinois                 85280\n",
      "Georgia                  80977\n",
      "Pennsylvania             78373\n",
      "Arizona                  72825\n",
      "Virginia                 68763\n",
      "Washington               62461\n",
      "Ohio                     59207\n",
      "New Jersey               48199\n",
      "Maryland                 46052\n",
      "Missouri                 45145\n",
      "Minnesota                43412\n",
      "Michigan                 42429\n",
      "Wisconsin                42390\n",
      "South Carolina           42367\n",
      "Tennessee                40964\n",
      "Massachusetts            38041\n",
      "Oklahoma                 37140\n",
      "Alabama                  34053\n",
      "Colorado                 32293\n",
      "Oregon                   32163\n",
      "Kentucky                 26316\n",
      "Louisiana                25815\n",
      "Arkansas                 23045\n",
      "Iowa                     23033\n",
      "New Mexico               21074\n",
      "Indiana                  18840\n",
      "Idaho                    16760\n",
      "Mississippi              16255\n",
      "Kansas                   14858\n",
      "Nevada                   14667\n",
      "Utah                     14557\n",
      "Connecticut              14008\n",
      "West Virginia            12309\n",
      "Montana                  10059\n",
      "Delaware                  8628\n",
      "Rhode Island              8157\n",
      "Hawaii                    7243\n",
      "District of Columbia      6625\n",
      "Nebraska                  6309\n",
      "Maine                     5065\n",
      "South Dakota              4690\n",
      "North Dakota              4268\n",
      "Wyoming                   4039\n",
      "New Hampshire             3642\n",
      "Puerto Rico               3126\n",
      "Vermont                   2600\n",
      "Alaska                    2581\n",
      "Virgin Islands             895\n",
      "Guam                       489\n",
      "New Brunswick                1\n",
      "Name: state, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Counts by states\n",
    "state_counts = realestate_df['state'].value_counts()\n",
    "\n",
    "print(\"State counts:\")\n",
    "print(state_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique states:\n",
      "['Puerto Rico' 'Virgin Islands' 'Massachusetts' 'Connecticut'\n",
      " 'New Hampshire' 'Vermont' 'New Jersey' 'New York' 'South Carolina'\n",
      " 'Tennessee' 'Rhode Island' 'Virginia' 'Wyoming' 'Maine' 'Georgia'\n",
      " 'Pennsylvania' 'West Virginia' 'Delaware' 'Louisiana' 'Ohio' 'California'\n",
      " 'Colorado' 'Maryland' 'Missouri' 'District of Columbia' 'Wisconsin'\n",
      " 'North Carolina' 'Kentucky' 'Michigan' 'Mississippi' 'Florida' 'Alabama'\n",
      " 'New Brunswick' nan 'Texas' 'Arkansas' 'Idaho' 'Indiana' 'Illinois'\n",
      " 'New Mexico' 'Iowa' 'Minnesota' 'South Dakota' 'Nebraska' 'North Dakota'\n",
      " 'Montana' 'Oklahoma' 'Kansas' 'Oregon' 'Utah' 'Nevada' 'Washington'\n",
      " 'Arizona' 'Hawaii' 'Guam' 'Alaska']\n"
     ]
    }
   ],
   "source": [
    "# List of unique states\n",
    "unique_states = realestate_df['state'].unique()\n",
    "\n",
    "print(\"Unique states:\")\n",
    "print(unique_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value counts per column:\n",
      "brokered_by         4533\n",
      "status                 0\n",
      "price               1541\n",
      "bed               481317\n",
      "bath              511771\n",
      "acre_lot          325589\n",
      "street             10866\n",
      "city                1407\n",
      "state                  8\n",
      "zip_code             299\n",
      "house_size        568484\n",
      "prev_sold_date    734297\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_value_counts =realestate_df.isna().sum()\n",
    "print(\"Missing value counts per column:\")\n",
    "print(missing_value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           status     price  bed  bath  acre_lot        city        state  \\\n",
      "0        for_sale  105000.0  3.0   2.0      0.12    Adjuntas  Puerto Rico   \n",
      "1        for_sale   80000.0  4.0   2.0      0.08    Adjuntas  Puerto Rico   \n",
      "2        for_sale   67000.0  2.0   1.0      0.15  Juana Diaz  Puerto Rico   \n",
      "3        for_sale  145000.0  4.0   2.0      0.10       Ponce  Puerto Rico   \n",
      "4        for_sale   65000.0  6.0   2.0      0.05    Mayaguez  Puerto Rico   \n",
      "...           ...       ...  ...   ...       ...         ...          ...   \n",
      "2226377      sold  359900.0  4.0   2.0      0.33    Richland   Washington   \n",
      "2226378      sold  350000.0  3.0   2.0      0.10    Richland   Washington   \n",
      "2226379      sold  440000.0  6.0   3.0      0.50    Richland   Washington   \n",
      "2226380      sold  179900.0  2.0   1.0      0.09    Richland   Washington   \n",
      "2226381      sold  580000.0  5.0   3.0      0.31    Richland   Washington   \n",
      "\n",
      "         zip_code  house_size prev_sold_date  \n",
      "0           601.0       920.0            NaN  \n",
      "1           601.0      1527.0            NaN  \n",
      "2           795.0       748.0            NaN  \n",
      "3           731.0      1800.0            NaN  \n",
      "4           680.0         NaN            NaN  \n",
      "...           ...         ...            ...  \n",
      "2226377   99354.0      3600.0     2022-03-25  \n",
      "2226378   99354.0      1616.0     2022-03-25  \n",
      "2226379   99354.0      3200.0     2022-03-24  \n",
      "2226380   99354.0       933.0     2022-03-24  \n",
      "2226381   99354.0      3615.0     2022-03-23  \n",
      "\n",
      "[2226382 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#Drop the following columns\" brokered_by, street\n",
    "# Delete columns \"brokered_by\" and \"street\"\n",
    "del realestate_df['brokered_by']\n",
    "del realestate_df['street']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(realestate_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           status     price  bed  bath  acre_lot           city        state  \\\n",
      "0        for_sale  105000.0  3.0   2.0      0.12       Adjuntas  Puerto Rico   \n",
      "1        for_sale   80000.0  4.0   2.0      0.08       Adjuntas  Puerto Rico   \n",
      "2        for_sale   67000.0  2.0   1.0      0.15     Juana Diaz  Puerto Rico   \n",
      "3        for_sale  145000.0  4.0   2.0      0.10          Ponce  Puerto Rico   \n",
      "5        for_sale  179000.0  4.0   3.0      0.46  San Sebastian  Puerto Rico   \n",
      "...           ...       ...  ...   ...       ...            ...          ...   \n",
      "2226377      sold  359900.0  4.0   2.0      0.33       Richland   Washington   \n",
      "2226378      sold  350000.0  3.0   2.0      0.10       Richland   Washington   \n",
      "2226379      sold  440000.0  6.0   3.0      0.50       Richland   Washington   \n",
      "2226380      sold  179900.0  2.0   1.0      0.09       Richland   Washington   \n",
      "2226381      sold  580000.0  5.0   3.0      0.31       Richland   Washington   \n",
      "\n",
      "         zip_code  house_size prev_sold_date  \n",
      "0           601.0       920.0            NaN  \n",
      "1           601.0      1527.0            NaN  \n",
      "2           795.0       748.0            NaN  \n",
      "3           731.0      1800.0            NaN  \n",
      "5           612.0      2520.0            NaN  \n",
      "...           ...         ...            ...  \n",
      "2226377   99354.0      3600.0     2022-03-25  \n",
      "2226378   99354.0      1616.0     2022-03-25  \n",
      "2226379   99354.0      3200.0     2022-03-24  \n",
      "2226380   99354.0       933.0     2022-03-24  \n",
      "2226381   99354.0      3615.0     2022-03-23  \n",
      "\n",
      "[1360347 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Specify columns to check for null values\n",
    "columns_to_check = ['price', 'bed', 'bath', 'status', 'acre_lot','city','state','zip_code','house_size']\n",
    "\n",
    "# Find and drop rows with null values in specified columns\n",
    "realestate_df.dropna(subset=columns_to_check, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(realestate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering dataset to exclude non-contiguous states and null values except for prev_sold_date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           status     price  bed  bath  acre_lot      city          state  \\\n",
      "3403     for_sale  180000.0  2.0   1.0      0.34    Agawam  Massachusetts   \n",
      "3408     for_sale  239900.0  3.0   1.0      0.46    Agawam  Massachusetts   \n",
      "3409     for_sale  525000.0  3.0   3.0      0.45    Agawam  Massachusetts   \n",
      "3410     for_sale  289900.0  3.0   2.0      0.36    Agawam  Massachusetts   \n",
      "3413     for_sale  275000.0  4.0   2.0      0.11    Agawam  Massachusetts   \n",
      "...           ...       ...  ...   ...       ...       ...            ...   \n",
      "2226377      sold  359900.0  4.0   2.0      0.33  Richland     Washington   \n",
      "2226378      sold  350000.0  3.0   2.0      0.10  Richland     Washington   \n",
      "2226379      sold  440000.0  6.0   3.0      0.50  Richland     Washington   \n",
      "2226380      sold  179900.0  2.0   1.0      0.09  Richland     Washington   \n",
      "2226381      sold  580000.0  5.0   3.0      0.31  Richland     Washington   \n",
      "\n",
      "         zip_code  house_size prev_sold_date  \n",
      "3403       1001.0       676.0            NaN  \n",
      "3408       1001.0      1196.0            NaN  \n",
      "3409       1001.0      2314.0     2014-06-25  \n",
      "3410       1001.0      1276.0     2012-10-12  \n",
      "3413       1001.0      1732.0            NaN  \n",
      "...           ...         ...            ...  \n",
      "2226377   99354.0      3600.0     2022-03-25  \n",
      "2226378   99354.0      1616.0     2022-03-25  \n",
      "2226379   99354.0      3200.0     2022-03-24  \n",
      "2226380   99354.0       933.0     2022-03-24  \n",
      "2226381   99354.0      3615.0     2022-03-23  \n",
      "\n",
      "[1353433 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# List of states to exclude (rows with these states will be removed)\n",
    "states_to_exclude = ['Guam', 'Puerto Rico', 'Virgin Islands','New Brunswick','Hawaii','Alaska']\n",
    "\n",
    "# Filter rows where state is NOT in the list of states to exclude\n",
    "filtered_df = realestate_df[~realestate_df['state'].isin(states_to_exclude)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique states:\n",
      "['Massachusetts' 'Connecticut' 'New Jersey' 'New York' 'New Hampshire'\n",
      " 'Vermont' 'Rhode Island' 'Wyoming' 'Maine' 'Pennsylvania' 'West Virginia'\n",
      " 'Delaware' 'Ohio' 'Maryland' 'Virginia' 'Colorado' 'District of Columbia'\n",
      " 'North Carolina' 'Kentucky' 'South Carolina' 'Tennessee' 'Georgia'\n",
      " 'Alabama' 'Florida' 'Mississippi' 'Texas' 'Missouri' 'Arkansas'\n",
      " 'Louisiana' 'Indiana' 'Illinois' 'Michigan' 'Wisconsin' 'Iowa'\n",
      " 'Minnesota' 'South Dakota' 'Nebraska' 'North Dakota' 'Montana' 'Idaho'\n",
      " 'Kansas' 'Oklahoma' 'New Mexico' 'Utah' 'Nevada' 'Washington' 'Oregon'\n",
      " 'Arizona' 'California']\n"
     ]
    }
   ],
   "source": [
    "# List of unique states\n",
    "unique_states = filtered_df['state'].unique()\n",
    "\n",
    "print(\"Unique states:\")\n",
    "print(unique_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status             object\n",
       "price             float64\n",
       "bed               float64\n",
       "bath              float64\n",
       "acre_lot          float64\n",
       "city               object\n",
       "state              object\n",
       "zip_code          float64\n",
       "house_size        float64\n",
       "prev_sold_date     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State counts:\n",
      "California              170947\n",
      "Texas                   145377\n",
      "Florida                 127658\n",
      "Arizona                  54488\n",
      "Pennsylvania             51944\n",
      "New York                 50958\n",
      "Georgia                  49240\n",
      "Illinois                 46943\n",
      "Washington               46435\n",
      "Virginia                 44236\n",
      "Ohio                     41195\n",
      "North Carolina           37341\n",
      "Maryland                 32980\n",
      "Minnesota                32746\n",
      "Missouri                 30157\n",
      "Massachusetts            28064\n",
      "Oklahoma                 26939\n",
      "Michigan                 22107\n",
      "Oregon                   21911\n",
      "Colorado                 19544\n",
      "New Jersey               19504\n",
      "Wisconsin                18454\n",
      "Tennessee                18310\n",
      "South Carolina           17182\n",
      "Iowa                     16497\n",
      "Kentucky                 15749\n",
      "Alabama                  14682\n",
      "Louisiana                14482\n",
      "New Mexico               11841\n",
      "Idaho                    11603\n",
      "Indiana                  11524\n",
      "Arkansas                 11376\n",
      "Kansas                   11214\n",
      "Nevada                   10118\n",
      "Utah                      9677\n",
      "Connecticut               9469\n",
      "Mississippi               7345\n",
      "West Virginia             7005\n",
      "Rhode Island              6563\n",
      "Delaware                  6093\n",
      "Montana                   5098\n",
      "Nebraska                  4275\n",
      "District of Columbia      2701\n",
      "North Dakota              2397\n",
      "Maine                     2273\n",
      "South Dakota              2029\n",
      "Wyoming                   1765\n",
      "New Hampshire             1734\n",
      "Vermont                   1263\n",
      "Name: state, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Counts by states\n",
    "state_counts = filtered_df['state'].value_counts()\n",
    "\n",
    "print(\"State counts:\")\n",
    "print(state_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path for the CSV output\n",
    "output_file_path = 'filtered_df.csv'\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "filtered_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a SQLite database\n",
    "\n",
    "filtered_df = pd.read_csv('filtered_df.csv')\n",
    "filtered_df\n",
    "\n",
    "# Create a SQLite database engine\n",
    "engine = create_engine('sqlite:///realestate.db')\n",
    "\n",
    "# Write DataFrame to SQLite database\n",
    "realestate_df.to_sql('filtered', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Confirm the data has been written by querying the database\n",
    "query = \"SELECT * FROM filtered LIMIT 5;\"  # Example query\n",
    "result = engine.execute(query)\n",
    "for row in result:\n",
    "    print(row)\n",
    "\n",
    "# Close the database connection\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read in the US_GeoCode csv file, make necessary changes and prepare for use in database and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   state&teritory   latitude   longitude                       Name\n",
      "0              AK  63.588753 -154.493062                     Alaska\n",
      "1              AL  32.318231  -86.902298                    Alabama\n",
      "2              AR  35.201050  -91.831833                   Arkansas\n",
      "3              AZ  34.048928 -111.093731                    Arizona\n",
      "4              CA  36.778261 -119.417932                 California\n",
      "..            ...        ...         ...                        ...\n",
      "56             MH   6.068394  171.989379           Marshall Islands\n",
      "57             MP  15.183333  145.750000   Northern Mariana Islands\n",
      "58             PW   7.514980  134.582520                      Palau\n",
      "59             PR -66.105720   18.466330                Puerto Rico\n",
      "60             VI  34.297878  -83.824066          US Virgin Islands\n",
      "\n",
      "[61 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Read and create a dataframe for the US_GeoCodes file\n",
    "# Specify the file path using raw string or escape backslashes\n",
    "file_path =(r\"C:\\Desktop\\Analysis Projects\\Testing_project_4\\Resources\\US_GeoCode.csv\")\n",
    "\n",
    "# Read data from CSV file into a DataFrame\n",
    "usgeocode_df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the DataFrame (optional)\n",
    "print(usgeocode_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state&teritory     object\n",
       "latitude          float64\n",
       "longitude         float64\n",
       "Name               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usgeocode_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>63.588753</td>\n",
       "      <td>-154.493062</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>32.318231</td>\n",
       "      <td>-86.902298</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR</td>\n",
       "      <td>35.201050</td>\n",
       "      <td>-91.831833</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AZ</td>\n",
       "      <td>34.048928</td>\n",
       "      <td>-111.093731</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>36.778261</td>\n",
       "      <td>-119.417932</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>MH</td>\n",
       "      <td>6.068394</td>\n",
       "      <td>171.989379</td>\n",
       "      <td>Marshall Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>MP</td>\n",
       "      <td>15.183333</td>\n",
       "      <td>145.750000</td>\n",
       "      <td>Northern Mariana Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>PW</td>\n",
       "      <td>7.514980</td>\n",
       "      <td>134.582520</td>\n",
       "      <td>Palau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>PR</td>\n",
       "      <td>-66.105720</td>\n",
       "      <td>18.466330</td>\n",
       "      <td>Puerto Rico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>VI</td>\n",
       "      <td>34.297878</td>\n",
       "      <td>-83.824066</td>\n",
       "      <td>US Virgin Islands</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state   latitude   longitude                       Name\n",
       "0     AK  63.588753 -154.493062                     Alaska\n",
       "1     AL  32.318231  -86.902298                    Alabama\n",
       "2     AR  35.201050  -91.831833                   Arkansas\n",
       "3     AZ  34.048928 -111.093731                    Arizona\n",
       "4     CA  36.778261 -119.417932                 California\n",
       "..   ...        ...         ...                        ...\n",
       "56    MH   6.068394  171.989379           Marshall Islands\n",
       "57    MP  15.183333  145.750000   Northern Mariana Islands\n",
       "58    PW   7.514980  134.582520                      Palau\n",
       "59    PR -66.105720   18.466330                Puerto Rico\n",
       "60    VI  34.297878  -83.824066          US Virgin Islands\n",
       "\n",
       "[61 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the column 'old_column_name' to 'new_column_name'\n",
    "usgeocode_df.rename(columns={'state&teritory' : 'state'}, inplace=True)\n",
    "usgeocode_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path for the CSV output\n",
    "output_file_path = 'usgeocode.csv'\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "usgeocode_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
