{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlalchemy.ext \n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy import create_engine, func\n",
    "from sqlalchemy.orm import Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE ORIGINAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data and create dataframe\n",
    "#NOTE: file too large to open in excel\n",
    "\n",
    "realestate_df = pd.read_csv(r\"C:\\Desktop\\Analysis Projects\\Project_4\\Resources\\realtor-data.zip.csv.zip\")\n",
    "realestate_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data types of the columns\n",
    "column_dtypes = realestate_df.dtypes\n",
    "print(\"Data types of columns:\")\n",
    "print(column_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking to see if there are duplicates in the dataset\n",
    "# Count duplicate rows based on all columns\n",
    "num_duplicate_rows = realestate_df.duplicated().sum()\n",
    "\n",
    "# Display the number of duplicate rows\n",
    "print(f\"Number of Duplicate Rows: {num_duplicate_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the original file as csv \n",
    "# Define the file path for the CSV output\n",
    "output_file_path = 'realestate_df.csv'\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "realestate_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previewing the dataframe from the original file\n",
    "realestate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REVIEWING AND PREPARING THE DATA TO BE FILTERED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts by states\n",
    "state_counts = realestate_df['state'].value_counts()\n",
    "\n",
    "print(\"State counts:\")\n",
    "print(state_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unique states\n",
    "unique_states = realestate_df['state'].unique()\n",
    "\n",
    "print(\"Unique states:\")\n",
    "print(unique_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_counts =realestate_df.isna().sum()\n",
    "print(\"Missing value counts per column:\")\n",
    "print(missing_value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the following columns\" brokered_by, street\n",
    "# Delete columns \"brokered_by\" and \"street\"\n",
    "del realestate_df['brokered_by']\n",
    "del realestate_df['street']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(realestate_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify columns to check for null values\n",
    "columns_to_check = ['price', 'bed', 'bath', 'status', 'acre_lot','city','state','zip_code','house_size']\n",
    "\n",
    "# Find and drop rows with null values in specified columns\n",
    "realestate_df.dropna(subset=columns_to_check, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(realestate_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering dataset to exclude non-contiguous states and null values except for prev_sold_date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of states to exclude (rows with these states will be removed)\n",
    "states_to_exclude = ['Guam', 'Puerto Rico', 'Virgin Islands','New Brunswick','Hawaii','Alaska']\n",
    "\n",
    "# Filter rows where state is NOT in the list of states to exclude\n",
    "filtered_df = realestate_df[~realestate_df['state'].isin(states_to_exclude)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unique states\n",
    "unique_states = filtered_df['state'].unique()\n",
    "\n",
    "print(\"Unique states:\")\n",
    "print(unique_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATION OF A NEW DATAFRAME FOR DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of a filtered data frame\n",
    "\n",
    "filtered_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts by states\n",
    "state_counts = filtered_df['state'].value_counts()\n",
    "\n",
    "print(\"State counts:\")\n",
    "print(state_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving to export new filtered dataframe as a csv file to be used in a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the file path for the CSV output\n",
    "output_file_path = 'filtered_df.csv'\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "filtered_df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Sqlachemy to create a sqlite database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data and create dataframe\n",
    "\n",
    "filtered_df = pd.read_csv(r\"C:\\Desktop\\Analysis Projects\\Project_4\\Resources\\filtered_df.csv\")\n",
    "#filtered_df\n",
    "\n",
    "# Create a SQLite database engine\n",
    "engine = create_engine('sqlite:///filtered_df.sqlite')\n",
    "\n",
    "# reflect an existing database into a new model\n",
    "Base=automap_base()\n",
    "\n",
    "# reflect the tables\n",
    "Base.prepare(autoload_with=engine)\n",
    "\n",
    "# Write DataFrame to SQLite database\n",
    "filtered_df.to_sql('realtor_filtered', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# Confirm the data has been written by querying the database\n",
    "query = \"SELECT * FROM realtor_filtered LIMIT 5;\"  # Example query\n",
    "result = engine.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the US_GeoCode csv file, renamed column header, and export it as a csv to be used in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read and create a dataframe for the US_GeoCodes file\n",
    "# Specify the file path using raw string or escape backslashes\n",
    "file_path =(r\"C:\\Desktop\\Analysis Projects\\Project_4\\Resources\\stateregion.csv\")\n",
    "\n",
    "# Read data from CSV file into a DataFrame\n",
    "stateregion_df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the DataFrame (optional)\n",
    "print(stateregion_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEMONSTRATING PLOTTING THE STATES COUNT IN A BAR CHART ORDERED BY STATE COUNTS\n",
    "\n",
    "state_counts = filtered_df['state'].value_counts()\n",
    "\n",
    "# Plotting the state counts as a bar chart using Matplotlib\n",
    "plt.figure(figsize=(15, 10))  # Set the figure size (width, height) in inches\n",
    "\n",
    "state_counts.plot(kind='bar', color='skyblue')  # Plotting a bar chart\n",
    "plt.title('Count of Properties by State')  # Adding a title to the plot\n",
    "plt.xlabel('State')  # Adding label to x-axis\n",
    "plt.ylabel('Count')  # Adding label to y-axis\n",
    "plt.xticks(rotation=90)  # Rotating x-axis labels for better readability\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Adding gridlines to y-axis\n",
    "\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MERGING THE REGION AND DIVISION COLUMNS TO THE FILTERED TABLE TO CREATE CHARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'realestate_filtered' with 'stateregion' on 'state' column\n",
    "# Merge based on different column names: 'state' in realestate_filtered and 'name' in stateregion\n",
    "#merged_df = pd.merge(filtered_df, stateregion_df[['region','division']], left_on='state', right_on='name', how='left')\n",
    "\n",
    "stateregion_subset = stateregion_df[['name', 'region', 'division']]\n",
    "merged_df = pd.merge(filtered_df, stateregion_subset, left_on='state', right_on='name', how='left')\n",
    "merged_df.drop('name', axis=1, inplace=True)\n",
    "\n",
    "# Display the merged dataframe\n",
    "print(merged_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_counts = merged_df['region'].value_counts()\n",
    "\n",
    "# Plotting the state counts as a bar chart using Matplotlib\n",
    "plt.figure(figsize=(15, 10))  # Set the figure size (width, height) in inches\n",
    "\n",
    "region_counts.plot(kind='bar', color='skyblue')  # Plotting a bar chart\n",
    "plt.title('Count of Properties by Region')  # Adding a title to the plot\n",
    "plt.xlabel('Region')  # Adding label to x-axis\n",
    "plt.ylabel('Count')  # Adding label to y-axis\n",
    "plt.xticks(rotation=45)  # Rotating x-axis labels for better readability\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Adding gridlines to y-axis\n",
    "\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "division_counts = merged_df['division'].value_counts()\n",
    "\n",
    "# Plotting the division counts as a bar chart using Matplotlib\n",
    "plt.figure(figsize=(15, 10))  # Set the figure size (width, height) in inches\n",
    "\n",
    "division_counts.plot(kind='bar', color='skyblue')  # Plotting a bar chart\n",
    "plt.title('Count of Properties by Division')  # Adding a title to the plot\n",
    "plt.xlabel('Division')  # Adding label to x-axis\n",
    "plt.ylabel('Count')  # Adding label to y-axis\n",
    "plt.xticks(rotation=45)  # Rotating x-axis labels for better readability\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Adding gridlines to y-axis\n",
    "\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
